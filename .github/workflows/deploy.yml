name: DEPLOY - RunPod AI Services

on:
  workflow_dispatch:
    inputs:
      service:
        description: 'Service to deploy'
        required: true
        default: 'translation_endpoint'
        type: choice
        options:
          - translation_endpoint
          - transcription_endpoint
          - speech_endpoint
          - mistral_endpoint
          - nllb_endpoint
          - unified_endpoint

env:
  DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}

jobs:
  deploy:
    name: Deploy ${{ matrix.service }}
    runs-on: ubuntu-latest
    
    strategy:
      fail-fast: false
      matrix:
        service: ${{ fromJson(format('["{0}"]', github.event.inputs.service)) }}
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: pip install requests
    
    - name: Deploy to RunPod
      env:
        RUNPOD_API_KEY: ${{ secrets.RUNPOD_API_KEY }}
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
        SERVICE_TYPE: ${{ matrix.service }}
        DOCKER_USERNAME: ${{ env.DOCKER_USERNAME }}
      run: |
        python3 << 'EOF'
        import os
        import sys
        import json
        import requests
        
        # Load config
        with open('runpod-config.json', 'r') as f:
            config = json.load(f)
        
        service_type = os.environ['SERVICE_TYPE']
        endpoint_config = config[service_type]
        template_config = config['template_config']
        
        # Setup
        api_key = os.environ['RUNPOD_API_KEY']
        hf_token = os.environ['HF_TOKEN']
        docker_username = os.environ['DOCKER_USERNAME']
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        base_url = 'https://rest.runpod.io/v1'
        
        # Variables
        endpoint_name = endpoint_config['endpoint_name']
        model_type_name = endpoint_config['model_type']
        gpu_types = endpoint_config['gpu_types'][0]
        idle_timeout = endpoint_config['idle_timeout']
        min_workers = endpoint_config['scaling']['min_workers']
        max_workers = endpoint_config['scaling']['max_workers']
        
        # Determine image name
        if 'image' in endpoint_config:
            target_image = endpoint_config['image'].replace('sawalle', docker_username)
        else:
            # Fallback for backward compatibility
            if service_type in ['mistral_endpoint', 'nllb_endpoint', 'unified_endpoint']:
                target_image = f"docker.io/{docker_username}/translation-service:latest"
            else:
                service_name = service_type.replace('_endpoint', '')
                target_image = f"docker.io/{docker_username}/{service_name}-service:latest"
        
        template_name = f"burkimbia-{model_type_name}-template"
        
        print(f"Deploying {endpoint_name} (service: {model_type_name})")
        print(f"GPU Type: {gpu_types}")
        print(f"Image: {target_image}")
        
        # Check/Create template
        print("\nChecking for existing template...")
        try:
            resp = requests.get(f'{base_url}/templates', headers=headers, timeout=30)
            resp.raise_for_status()
            templates = resp.json()
            
            template_id = None
            for template in templates:
                if template.get('name') == template_name:
                    template_id = template.get('id')
                    break
            
            if not template_id:
                print(f"Creating template: {template_name}")
                template_payload = {
                    "name": template_name,
                    "imageName": target_image,
                    "isServerless": True,
                    "containerDiskInGb": template_config['container_disk_size'],
                    "volumeInGb": template_config['volume_size'],
                    "volumeMountPath": "/runpod-volume",
                    "env": {
                        "HF_TOKEN": hf_token,
                        "MODEL_TYPE": model_type_name,
                        **endpoint_config.get('env', {})
                    }
                }
                
                resp = requests.post(f'{base_url}/templates', headers=headers, json=template_payload, timeout=30)
                resp.raise_for_status()
                template_result = resp.json()
                template_id = template_result.get('id')
                
                if not template_id:
                    print(f"âŒ Template creation failed: {template_result}")
                    sys.exit(1)
                print(f"âœ… Template created: {template_id}")
            else:
                print(f"âœ… Template exists: {template_id}")
        
        except requests.exceptions.RequestException as e:
            print(f"âŒ Error with templates API: {e}")
            if hasattr(e.response, 'text'):
                print(f"Response: {e.response.text}")
            sys.exit(1)
        
        # Check if endpoint already exists
        print("\nChecking for existing endpoint...")
        try:
            resp = requests.get(f'{base_url}/endpoints', headers=headers, timeout=30)
            resp.raise_for_status()
            endpoints = resp.json()
            
            endpoint_id = None
            for endpoint in endpoints:
                if endpoint.get('name') == endpoint_name:
                    endpoint_id = endpoint.get('id')
                    break
            
            if endpoint_id:
                print(f"âš ï¸  Endpoint already exists: {endpoint_id}")
                print(f"ðŸŒ URL: https://api.runpod.ai/v1/{endpoint_id}/run")
                sys.exit(0)
        
        except requests.exceptions.RequestException as e:
            print(f"âŒ Error checking endpoints: {e}")
            if hasattr(e.response, 'text'):
                print(f"Response: {e.response.text}")
            sys.exit(1)
        
        # Create endpoint
        print(f"\nCreating endpoint...")
        try:
            endpoint_payload = {
                "name": endpoint_name,
                "templateId": template_id,
                "gpuTypeIds": [gpu_types],
                "idleTimeout": idle_timeout,
                "workersMin": min_workers,
                "workersMax": max_workers
            }
            
            resp = requests.post(f'{base_url}/endpoints', headers=headers, json=endpoint_payload, timeout=30)
            resp.raise_for_status()
            endpoint_result = resp.json()
            endpoint_id = endpoint_result.get('id')
            
            if endpoint_id:
                print(f"âœ… Endpoint deployed: {endpoint_id}")
                print(f"ðŸŒ URL: https://api.runpod.ai/v1/{endpoint_id}/run")
                print(f"ðŸ“Š Service: {model_type_name}")
                print(f"ðŸ–¼ï¸  Image: {target_image}")
            else:
                print(f"âŒ Deploy failed: {endpoint_result}")
                sys.exit(1)
        
        except requests.exceptions.RequestException as e:
            print(f"âŒ Error creating endpoint: {e}")
            if hasattr(e.response, 'text'):
                print(f"Response: {e.response.text}")
            sys.exit(1)
        
        EOF