# ğŸ¤– AI Services Infrastructure - BurkimbIA

Une infrastructure complÃ¨te de services IA pour la traduction, transcription et synthÃ¨se vocale en moorÃ© et franÃ§ais.

## ğŸ—ï¸ Architecture des Services

```
ğŸ“¦ AI Services Infrastructure
â”œâ”€â”€ ğŸ”¤ translation/          # Service de traduction (NLLB + Mistral)
â”œâ”€â”€ ğŸ™ï¸  transcription/        # Service de transcription (Whisper)
â”œâ”€â”€ ğŸ”Š speech/               # Service de synthÃ¨se vocale (TTS)
â””â”€â”€ ğŸš€ CI/CD Pipeline        # DÃ©ploiement automatisÃ©
```

## ğŸ³ Services Disponibles

### ğŸ”¤ **Translation Service**
- **ModÃ¨les**: NLLB-600M + Mistral-7B-SACHI
- **Langues**: FranÃ§ais â†” MoorÃ©
- **Image**: `docker.io/username/translation-service:latest`

### ğŸ™ï¸ **Transcription Service**
- **ModÃ¨le**: BIA-WHISPER-LARGE-SACHI_V2
- **Fonction**: Audio â†’ Texte (moorÃ©, franÃ§ais)
- **Image**: `docker.io/username/transcription-service:latest`

### ğŸ”Š **Speech Service** *(En dÃ©veloppement)*
- **ModÃ¨les**: Coqui TTS, XTTS
- **Fonction**: Texte â†’ Audio (moorÃ©, franÃ§ais)
- **Image**: `docker.io/username/speech-service:latest`

## ğŸš€ CI/CD Pipeline

### **Build Automatique**
```bash
# Build tous les services
gh workflow run build.yml --field service=all

# Build service spÃ©cifique
gh workflow run build.yml --field service=translation
gh workflow run build.yml --field service=transcription
gh workflow run build.yml --field service=speech
```

### **DÃ©ploiement RunPod**
```bash
# DÃ©ployer service de traduction
gh workflow run deploy.yml --field service=translation_endpoint

# DÃ©ployer service de transcription  
gh workflow run deploy.yml --field service=transcription_endpoint

# DÃ©ployer service de speech
gh workflow run deploy.yml --field service=speech_endpoint
```

## ğŸ”§ Configuration des Services

### **Variables d'environnement requises**
```bash
HF_TOKEN=your_huggingface_token
RUNPOD_API_KEY=your_runpod_api_key
DOCKER_USERNAME=your_docker_username
DOCKER_PASSWORD=your_docker_password
```

### **GPU Configuration**
- **Translation**: NVIDIA A40 (3 workers max)
- **Transcription**: NVIDIA A40 (2 workers max) 
- **Speech**: NVIDIA A40 (2 workers max)

## ğŸ“Š Endpoints de Production

### **Translation API**
```json
POST https://api.runpod.ai/v1/{endpoint_id}/run
Content-Type: application/json

{
  "input": {
    "text": "Bonjour comment allez-vous?",
    "src_lang": "fra_Latn",
    "tgt_lang": "moor_Latn",
    "model": "nllb"
  }
}
```

### **Transcription API**
```json
POST https://api.runpod.ai/v1/{endpoint_id}/run
Content-Type: application/json

{
  "input": {
    "audio_url": "https://example.com/audio.wav",
    "model": "burkimbia/BIA-WHISPER-LARGE-SACHI_V2",
    "language": "moor"
  }
}
```

## ğŸ› ï¸ DÃ©veloppement Local

### **Build et Test Locaux**
```bash
# Translation Service
cd translation/
docker build --build-arg HF_TOKEN=$HF_TOKEN -t translation-service .
docker run -p 8000:8000 -e HF_TOKEN=$HF_TOKEN translation-service

# Transcription Service  
cd transcription/
docker build --build-arg HF_TOKEN=$HF_TOKEN -t transcription-service .
docker run -p 8001:8000 -e HF_TOKEN=$HF_TOKEN transcription-service

# Speech Service
cd speech/
docker build --build-arg HF_TOKEN=$HF_TOKEN -t speech-service .
docker run -p 8002:8000 -e HF_TOKEN=$HF_TOKEN speech-service
```

## ğŸ“‹ ModÃ¨les UtilisÃ©s

| Service | ModÃ¨le | Taille | Fonction |
|---------|--------|--------|----------|
| Translation | `burkimbia/BIA-NLLB-600M-5E` | 600M | Neural MT (FranÃ§aisâ†”MoorÃ©) |
| Translation | `burkimbia/BIA-MISTRAL-7B-SACHI` | 7B | Instruction-tuned MT |
| Transcription | `burkimbia/BIA-WHISPER-LARGE-SACHI_V2` | 1.5B | ASR (Audioâ†’Texte) |
| Speech | *Ã€ dÃ©finir* | - | TTS (Texteâ†’Audio) |

## ğŸ”„ Workflow de DÃ©ploiement

1. **Push Code** â†’ GitHub dÃ©clenche le build automatique
2. **Build Docker** â†’ Images crÃ©Ã©es pour chaque service modifiÃ©
3. **Push Registry** â†’ Images envoyÃ©es vers Docker Hub
4. **Deploy RunPod** â†’ Endpoints crÃ©Ã©s/mis Ã  jour automatiquement
5. **Health Check** â†’ VÃ©rification du bon fonctionnement

## ğŸ“ˆ Monitoring et ObservabilitÃ©

- **Logs**: Disponibles via RunPod dashboard
- **MÃ©triques**: Temps de rÃ©ponse, utilisation GPU
- **Alerts**: Ã‰checs de dÃ©ploiement via GitHub Actions

## ğŸš§ Roadmap

- [x] Service de traduction (NLLB + Mistral)
- [x] Service de transcription (Whisper)
- [x] CI/CD multi-services
- [ ] Service de synthÃ¨se vocale (TTS)
- [ ] API Gateway unifiÃ©e
- [ ] Monitoring avancÃ©
- [ ] Auto-scaling intelligent


